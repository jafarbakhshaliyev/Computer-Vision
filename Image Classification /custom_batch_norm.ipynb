{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21KYaJtxxGvl"
      },
      "source": [
        "# Custom Batch Normalization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hizFMVF6LW9v"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class MyBatchNormalization(layers.Layer):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(MyBatchNormalization, self).__init__()\n",
        "\n",
        "  def build(self, input_shape):   \n",
        "    self.alpha = self.add_weight(shape = (input_shape[3]), initializer = 'ones', trainable = True)\n",
        "    self.beta = self.add_weight(shape = (input_shape[3]), initializer = 'zeros', trainable = True)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    mean = tf.math.reduce_mean(inputs, axis = [0,1,2], keepdims = True)\n",
        "    stddev = tf.math.reduce_std(inputs, axis = [0,1,2], keepdims = True)\n",
        "    normalized = (inputs - mean)/stddev\n",
        "    return self.alpha*normalized + self.beta  \n",
        "\n",
        "\n",
        "def define_model():\n",
        "    inputs = keras.Input(shape=(28,28,1))\n",
        "\n",
        "    K = 20 # number of convolution layers per block\n",
        "    L = 3  # number of blocks\n",
        "    x = inputs\n",
        "    for i in range(0,L):\n",
        "        for j in range(0,K):\n",
        "            x = MyBatchNormalization()(x)\n",
        "            x = layers.Conv2D(32, 3, activation=\"relu\",padding=\"same\")(x)\n",
        "        x = layers.MaxPooling2D(3)(x)\n",
        "    x = layers.GlobalMaxPooling2D()(x)\n",
        "    outputs = layers.Dense(10,activation='softmax')(x)\n",
        "\n",
        "    model = keras.Model(inputs,outputs)\n",
        "    model.summary() # show model overview\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrNe7WQsOg9s",
        "outputId": "b09b95a7-0775-42af-e48b-ab604333981f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " my_batch_normalization_60 (  (None, 28, 28, 1)        2         \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_60 (Conv2D)          (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " my_batch_normalization_61 (  (None, 28, 28, 32)       64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_61 (Conv2D)          (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " my_batch_normalization_62 (  (None, 28, 28, 32)       64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_62 (Conv2D)          (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " my_batch_normalization_63 (  (None, 28, 28, 32)       64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_63 (Conv2D)          (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " my_batch_normalization_64 (  (None, 28, 28, 32)       64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_64 (Conv2D)          (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " my_batch_normalization_65 (  (None, 28, 28, 32)       64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_65 (Conv2D)          (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " my_batch_normalization_66 (  (None, 28, 28, 32)       64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_66 (Conv2D)          (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " my_batch_normalization_67 (  (None, 28, 28, 32)       64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_67 (Conv2D)          (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " my_batch_normalization_68 (  (None, 28, 28, 32)       64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_68 (Conv2D)          (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " my_batch_normalization_69 (  (None, 28, 28, 32)       64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_69 (Conv2D)          (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " my_batch_normalization_70 (  (None, 28, 28, 32)       64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_70 (Conv2D)          (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " my_batch_normalization_71 (  (None, 28, 28, 32)       64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_71 (Conv2D)          (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " my_batch_normalization_72 (  (None, 28, 28, 32)       64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_72 (Conv2D)          (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " my_batch_normalization_73 (  (None, 28, 28, 32)       64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_73 (Conv2D)          (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " my_batch_normalization_74 (  (None, 28, 28, 32)       64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_74 (Conv2D)          (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " my_batch_normalization_75 (  (None, 28, 28, 32)       64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_75 (Conv2D)          (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " my_batch_normalization_76 (  (None, 28, 28, 32)       64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_76 (Conv2D)          (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " my_batch_normalization_77 (  (None, 28, 28, 32)       64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_77 (Conv2D)          (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " my_batch_normalization_78 (  (None, 28, 28, 32)       64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_78 (Conv2D)          (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " my_batch_normalization_79 (  (None, 28, 28, 32)       64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_79 (Conv2D)          (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 9, 9, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " my_batch_normalization_80 (  (None, 9, 9, 32)         64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_80 (Conv2D)          (None, 9, 9, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_81 (  (None, 9, 9, 32)         64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_81 (Conv2D)          (None, 9, 9, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_82 (  (None, 9, 9, 32)         64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_82 (Conv2D)          (None, 9, 9, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_83 (  (None, 9, 9, 32)         64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_83 (Conv2D)          (None, 9, 9, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_84 (  (None, 9, 9, 32)         64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_84 (Conv2D)          (None, 9, 9, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_85 (  (None, 9, 9, 32)         64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_85 (Conv2D)          (None, 9, 9, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_86 (  (None, 9, 9, 32)         64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_86 (Conv2D)          (None, 9, 9, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_87 (  (None, 9, 9, 32)         64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_87 (Conv2D)          (None, 9, 9, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_88 (  (None, 9, 9, 32)         64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_88 (Conv2D)          (None, 9, 9, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_89 (  (None, 9, 9, 32)         64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_89 (Conv2D)          (None, 9, 9, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_90 (  (None, 9, 9, 32)         64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_90 (Conv2D)          (None, 9, 9, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_91 (  (None, 9, 9, 32)         64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_91 (Conv2D)          (None, 9, 9, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_92 (  (None, 9, 9, 32)         64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_92 (Conv2D)          (None, 9, 9, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_93 (  (None, 9, 9, 32)         64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_93 (Conv2D)          (None, 9, 9, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_94 (  (None, 9, 9, 32)         64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_94 (Conv2D)          (None, 9, 9, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_95 (  (None, 9, 9, 32)         64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_95 (Conv2D)          (None, 9, 9, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_96 (  (None, 9, 9, 32)         64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_96 (Conv2D)          (None, 9, 9, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_97 (  (None, 9, 9, 32)         64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_97 (Conv2D)          (None, 9, 9, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_98 (  (None, 9, 9, 32)         64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_98 (Conv2D)          (None, 9, 9, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_99 (  (None, 9, 9, 32)         64        \n",
            " MyBatchNormalization)                                           \n",
            "                                                                 \n",
            " conv2d_99 (Conv2D)          (None, 9, 9, 32)          9248      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 3, 3, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " my_batch_normalization_100   (None, 3, 3, 32)         64        \n",
            " (MyBatchNormalization)                                          \n",
            "                                                                 \n",
            " conv2d_100 (Conv2D)         (None, 3, 3, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_101   (None, 3, 3, 32)         64        \n",
            " (MyBatchNormalization)                                          \n",
            "                                                                 \n",
            " conv2d_101 (Conv2D)         (None, 3, 3, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_102   (None, 3, 3, 32)         64        \n",
            " (MyBatchNormalization)                                          \n",
            "                                                                 \n",
            " conv2d_102 (Conv2D)         (None, 3, 3, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_103   (None, 3, 3, 32)         64        \n",
            " (MyBatchNormalization)                                          \n",
            "                                                                 \n",
            " conv2d_103 (Conv2D)         (None, 3, 3, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_104   (None, 3, 3, 32)         64        \n",
            " (MyBatchNormalization)                                          \n",
            "                                                                 \n",
            " conv2d_104 (Conv2D)         (None, 3, 3, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_105   (None, 3, 3, 32)         64        \n",
            " (MyBatchNormalization)                                          \n",
            "                                                                 \n",
            " conv2d_105 (Conv2D)         (None, 3, 3, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_106   (None, 3, 3, 32)         64        \n",
            " (MyBatchNormalization)                                          \n",
            "                                                                 \n",
            " conv2d_106 (Conv2D)         (None, 3, 3, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_107   (None, 3, 3, 32)         64        \n",
            " (MyBatchNormalization)                                          \n",
            "                                                                 \n",
            " conv2d_107 (Conv2D)         (None, 3, 3, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_108   (None, 3, 3, 32)         64        \n",
            " (MyBatchNormalization)                                          \n",
            "                                                                 \n",
            " conv2d_108 (Conv2D)         (None, 3, 3, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_109   (None, 3, 3, 32)         64        \n",
            " (MyBatchNormalization)                                          \n",
            "                                                                 \n",
            " conv2d_109 (Conv2D)         (None, 3, 3, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_110   (None, 3, 3, 32)         64        \n",
            " (MyBatchNormalization)                                          \n",
            "                                                                 \n",
            " conv2d_110 (Conv2D)         (None, 3, 3, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_111   (None, 3, 3, 32)         64        \n",
            " (MyBatchNormalization)                                          \n",
            "                                                                 \n",
            " conv2d_111 (Conv2D)         (None, 3, 3, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_112   (None, 3, 3, 32)         64        \n",
            " (MyBatchNormalization)                                          \n",
            "                                                                 \n",
            " conv2d_112 (Conv2D)         (None, 3, 3, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_113   (None, 3, 3, 32)         64        \n",
            " (MyBatchNormalization)                                          \n",
            "                                                                 \n",
            " conv2d_113 (Conv2D)         (None, 3, 3, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_114   (None, 3, 3, 32)         64        \n",
            " (MyBatchNormalization)                                          \n",
            "                                                                 \n",
            " conv2d_114 (Conv2D)         (None, 3, 3, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_115   (None, 3, 3, 32)         64        \n",
            " (MyBatchNormalization)                                          \n",
            "                                                                 \n",
            " conv2d_115 (Conv2D)         (None, 3, 3, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_116   (None, 3, 3, 32)         64        \n",
            " (MyBatchNormalization)                                          \n",
            "                                                                 \n",
            " conv2d_116 (Conv2D)         (None, 3, 3, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_117   (None, 3, 3, 32)         64        \n",
            " (MyBatchNormalization)                                          \n",
            "                                                                 \n",
            " conv2d_117 (Conv2D)         (None, 3, 3, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_118   (None, 3, 3, 32)         64        \n",
            " (MyBatchNormalization)                                          \n",
            "                                                                 \n",
            " conv2d_118 (Conv2D)         (None, 3, 3, 32)          9248      \n",
            "                                                                 \n",
            " my_batch_normalization_119   (None, 3, 3, 32)         64        \n",
            " (MyBatchNormalization)                                          \n",
            "                                                                 \n",
            " conv2d_119 (Conv2D)         (None, 3, 3, 32)          9248      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 1, 1, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " global_max_pooling2d_1 (Glo  (None, 32)               0         \n",
            " balMaxPooling2D)                                                \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 550,060\n",
            "Trainable params: 550,060\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "938/938 [==============================] - 120s 76ms/step - loss: 2.1449 - accuracy: 0.1777\n",
            "Epoch 2/100\n",
            "938/938 [==============================] - 72s 77ms/step - loss: 1.2059 - accuracy: 0.5151\n",
            "Epoch 3/100\n",
            "938/938 [==============================] - 72s 77ms/step - loss: 0.8412 - accuracy: 0.6717\n",
            "Epoch 4/100\n",
            "938/938 [==============================] - 72s 76ms/step - loss: 0.7019 - accuracy: 0.7329\n",
            "Epoch 5/100\n",
            "938/938 [==============================] - 72s 77ms/step - loss: 0.6236 - accuracy: 0.7641\n",
            "Epoch 6/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 0.5675 - accuracy: 0.7897\n",
            "Epoch 7/100\n",
            "938/938 [==============================] - 72s 77ms/step - loss: 0.5216 - accuracy: 0.8093\n",
            "Epoch 8/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 0.4904 - accuracy: 0.8219\n",
            "Epoch 9/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 0.4665 - accuracy: 0.8301\n",
            "Epoch 10/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 0.4415 - accuracy: 0.8390\n",
            "Epoch 11/100\n",
            "938/938 [==============================] - 72s 76ms/step - loss: 0.4244 - accuracy: 0.8466\n",
            "Epoch 12/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 0.4212 - accuracy: 0.8480\n",
            "Epoch 13/100\n",
            "938/938 [==============================] - 72s 76ms/step - loss: 0.3890 - accuracy: 0.8594\n",
            "Epoch 14/100\n",
            "938/938 [==============================] - 72s 77ms/step - loss: 0.3976 - accuracy: 0.8565\n",
            "Epoch 15/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 0.3883 - accuracy: 0.8591\n",
            "Epoch 16/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 0.3436 - accuracy: 0.8761\n",
            "Epoch 17/100\n",
            "938/938 [==============================] - 72s 76ms/step - loss: 0.3370 - accuracy: 0.8788\n",
            "Epoch 18/100\n",
            "938/938 [==============================] - 72s 76ms/step - loss: 0.3434 - accuracy: 0.8784\n",
            "Epoch 19/100\n",
            "938/938 [==============================] - 71s 75ms/step - loss: 0.3042 - accuracy: 0.8940\n",
            "Epoch 20/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 0.3154 - accuracy: 0.8877\n",
            "Epoch 21/100\n",
            "938/938 [==============================] - 72s 77ms/step - loss: 0.2979 - accuracy: 0.8955\n",
            "Epoch 22/100\n",
            "938/938 [==============================] - 72s 77ms/step - loss: 0.2812 - accuracy: 0.9005\n",
            "Epoch 23/100\n",
            "938/938 [==============================] - 70s 75ms/step - loss: 0.2764 - accuracy: 0.9031\n",
            "Epoch 24/100\n",
            "938/938 [==============================] - 72s 76ms/step - loss: 0.2685 - accuracy: 0.9055\n",
            "Epoch 25/100\n",
            "938/938 [==============================] - 72s 77ms/step - loss: 0.2588 - accuracy: 0.9086\n",
            "Epoch 26/100\n",
            "938/938 [==============================] - 72s 76ms/step - loss: 1.6454 - accuracy: 0.3602\n",
            "Epoch 27/100\n",
            "938/938 [==============================] - 72s 76ms/step - loss: 2.3028 - accuracy: 0.0981\n",
            "Epoch 28/100\n",
            "938/938 [==============================] - 72s 76ms/step - loss: 2.3027 - accuracy: 0.0993\n",
            "Epoch 29/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 2.3027 - accuracy: 0.0967\n",
            "Epoch 30/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 2.3027 - accuracy: 0.0993\n",
            "Epoch 31/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 2.3027 - accuracy: 0.0999\n",
            "Epoch 32/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 2.3027 - accuracy: 0.0994\n",
            "Epoch 33/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 2.3027 - accuracy: 0.0992\n",
            "Epoch 34/100\n",
            "938/938 [==============================] - 72s 77ms/step - loss: 2.3027 - accuracy: 0.0972\n",
            "Epoch 35/100\n",
            "938/938 [==============================] - 73s 78ms/step - loss: 2.3027 - accuracy: 0.0998\n",
            "Epoch 36/100\n",
            "938/938 [==============================] - 72s 77ms/step - loss: 2.3028 - accuracy: 0.0981\n",
            "Epoch 37/100\n",
            "938/938 [==============================] - 72s 77ms/step - loss: 2.3027 - accuracy: 0.0988\n",
            "Epoch 38/100\n",
            "938/938 [==============================] - 72s 76ms/step - loss: 2.3028 - accuracy: 0.0979\n",
            "Epoch 39/100\n",
            "938/938 [==============================] - 72s 77ms/step - loss: 2.3027 - accuracy: 0.0986\n",
            "Epoch 40/100\n",
            "938/938 [==============================] - 72s 77ms/step - loss: 2.3027 - accuracy: 0.0988\n",
            "Epoch 41/100\n",
            "938/938 [==============================] - 72s 77ms/step - loss: 2.3027 - accuracy: 0.0997\n",
            "Epoch 42/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 2.3027 - accuracy: 0.0966\n",
            "Epoch 43/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 2.3027 - accuracy: 0.0979\n",
            "Epoch 44/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 2.3027 - accuracy: 0.1007\n",
            "Epoch 45/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 2.3027 - accuracy: 0.0989\n",
            "Epoch 46/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 2.3027 - accuracy: 0.0984\n",
            "Epoch 47/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 2.3027 - accuracy: 0.0981\n",
            "Epoch 48/100\n",
            "938/938 [==============================] - 70s 74ms/step - loss: 2.3027 - accuracy: 0.0981\n",
            "Epoch 49/100\n",
            "938/938 [==============================] - 70s 74ms/step - loss: 2.3027 - accuracy: 0.0989\n",
            "Epoch 50/100\n",
            "938/938 [==============================] - 71s 75ms/step - loss: 2.3027 - accuracy: 0.0986\n",
            "Epoch 51/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 2.3027 - accuracy: 0.0973\n",
            "Epoch 52/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 2.3027 - accuracy: 0.0999\n",
            "Epoch 53/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 2.3027 - accuracy: 0.0976\n",
            "Epoch 54/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 2.3027 - accuracy: 0.0969\n",
            "Epoch 55/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 2.3027 - accuracy: 0.0992\n",
            "Epoch 56/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 2.3027 - accuracy: 0.0979\n",
            "Epoch 57/100\n",
            "938/938 [==============================] - 71s 75ms/step - loss: 2.3027 - accuracy: 0.0985\n",
            "Epoch 58/100\n",
            "938/938 [==============================] - 72s 76ms/step - loss: 2.3027 - accuracy: 0.0990\n",
            "Epoch 59/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 2.3027 - accuracy: 0.0969\n",
            "Epoch 60/100\n",
            "938/938 [==============================] - 70s 75ms/step - loss: 2.3027 - accuracy: 0.0986\n",
            "Epoch 61/100\n",
            "938/938 [==============================] - 69s 73ms/step - loss: 2.3027 - accuracy: 0.0985\n",
            "Epoch 62/100\n",
            "938/938 [==============================] - 70s 74ms/step - loss: 2.3027 - accuracy: 0.0970\n",
            "Epoch 63/100\n",
            "938/938 [==============================] - 71s 75ms/step - loss: 2.3028 - accuracy: 0.0971\n",
            "Epoch 64/100\n",
            "938/938 [==============================] - 70s 74ms/step - loss: 2.3027 - accuracy: 0.0984\n",
            "Epoch 65/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 2.3027 - accuracy: 0.0999\n",
            "Epoch 66/100\n",
            "938/938 [==============================] - 70s 74ms/step - loss: 2.3027 - accuracy: 0.0974\n",
            "Epoch 67/100\n",
            "938/938 [==============================] - 71s 75ms/step - loss: 2.3027 - accuracy: 0.0994\n",
            "Epoch 68/100\n",
            "938/938 [==============================] - 70s 74ms/step - loss: 2.3027 - accuracy: 0.0981\n",
            "Epoch 69/100\n",
            "938/938 [==============================] - 70s 74ms/step - loss: 2.3027 - accuracy: 0.0984\n",
            "Epoch 70/100\n",
            "938/938 [==============================] - 70s 75ms/step - loss: 2.3027 - accuracy: 0.0997\n",
            "Epoch 71/100\n",
            "938/938 [==============================] - 70s 75ms/step - loss: 2.3027 - accuracy: 0.0983\n",
            "Epoch 72/100\n",
            "938/938 [==============================] - 70s 75ms/step - loss: 2.3027 - accuracy: 0.0975\n",
            "Epoch 73/100\n",
            "938/938 [==============================] - 69s 74ms/step - loss: 2.3027 - accuracy: 0.0988\n",
            "Epoch 74/100\n",
            "938/938 [==============================] - 70s 74ms/step - loss: 2.3027 - accuracy: 0.0982\n",
            "Epoch 75/100\n",
            "938/938 [==============================] - 71s 75ms/step - loss: 2.3027 - accuracy: 0.0970\n",
            "Epoch 76/100\n",
            "938/938 [==============================] - 70s 75ms/step - loss: 2.3027 - accuracy: 0.0990\n",
            "Epoch 77/100\n",
            "938/938 [==============================] - 70s 75ms/step - loss: 2.3027 - accuracy: 0.0979\n",
            "Epoch 78/100\n",
            "938/938 [==============================] - 70s 74ms/step - loss: 2.3027 - accuracy: 0.0964\n",
            "Epoch 79/100\n",
            "938/938 [==============================] - 70s 74ms/step - loss: 2.3027 - accuracy: 0.0980\n",
            "Epoch 80/100\n",
            "938/938 [==============================] - 69s 74ms/step - loss: 2.3027 - accuracy: 0.0991\n",
            "Epoch 81/100\n",
            "938/938 [==============================] - 70s 75ms/step - loss: 2.3027 - accuracy: 0.0986\n",
            "Epoch 82/100\n",
            "938/938 [==============================] - 70s 75ms/step - loss: 2.3028 - accuracy: 0.0977\n",
            "Epoch 83/100\n",
            "938/938 [==============================] - 70s 75ms/step - loss: 2.3027 - accuracy: 0.0994\n",
            "Epoch 84/100\n",
            "938/938 [==============================] - 70s 75ms/step - loss: 2.3027 - accuracy: 0.1004\n",
            "Epoch 85/100\n",
            "938/938 [==============================] - 69s 74ms/step - loss: 2.3027 - accuracy: 0.1004\n",
            "Epoch 86/100\n",
            "938/938 [==============================] - 70s 74ms/step - loss: 2.3027 - accuracy: 0.0981\n",
            "Epoch 87/100\n",
            "938/938 [==============================] - 70s 75ms/step - loss: 2.3027 - accuracy: 0.0989\n",
            "Epoch 88/100\n",
            "938/938 [==============================] - 69s 74ms/step - loss: 2.3027 - accuracy: 0.0979\n",
            "Epoch 89/100\n",
            "938/938 [==============================] - 70s 74ms/step - loss: 2.3027 - accuracy: 0.0985\n",
            "Epoch 90/100\n",
            "938/938 [==============================] - 70s 74ms/step - loss: 2.3027 - accuracy: 0.0986\n",
            "Epoch 91/100\n",
            "938/938 [==============================] - 70s 75ms/step - loss: 2.3027 - accuracy: 0.0990\n",
            "Epoch 92/100\n",
            "938/938 [==============================] - 69s 74ms/step - loss: 2.3027 - accuracy: 0.0972\n",
            "Epoch 93/100\n",
            "938/938 [==============================] - 71s 75ms/step - loss: 2.3027 - accuracy: 0.0972\n",
            "Epoch 94/100\n",
            "938/938 [==============================] - 70s 75ms/step - loss: 2.3027 - accuracy: 0.0981\n",
            "Epoch 95/100\n",
            "938/938 [==============================] - 70s 75ms/step - loss: 2.3027 - accuracy: 0.0984\n",
            "Epoch 96/100\n",
            "938/938 [==============================] - 70s 75ms/step - loss: 2.3027 - accuracy: 0.0966\n",
            "Epoch 97/100\n",
            "938/938 [==============================] - 70s 74ms/step - loss: 2.3027 - accuracy: 0.0984\n",
            "Epoch 98/100\n",
            "938/938 [==============================] - 70s 74ms/step - loss: 2.3027 - accuracy: 0.0996\n",
            "Epoch 99/100\n",
            "938/938 [==============================] - 70s 75ms/step - loss: 2.3027 - accuracy: 0.0978\n",
            "Epoch 100/100\n",
            "938/938 [==============================] - 71s 76ms/step - loss: 2.3027 - accuracy: 0.0987\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7af97df9a0>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load and preprocess training data (Fashion-MNIST)\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
        "\n",
        "# Define and train model\n",
        "model = define_model()\n",
        "model.compile(loss=keras.losses.CategoricalCrossentropy(),optimizer=keras.optimizers.Adam(),metrics=[\"accuracy\"])\n",
        "model.fit(train_images,train_labels, batch_size=64, epochs=100)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
